为了项目协作以及分享，我们需要将模型（及其参数和数据集）保存到某些平台上。由于GitHub免费用户的LFS文件大小限制为2GB，对于一些较大的数据集或模型不够用，所以笔者选择将模型保存到[Hugging Face](https://huggingface.co)。

将模型妥善保存的步骤如下：

### 第一步

保证模型在本地能正常训练和推理，主要检查以下环境依赖。
* Python虚拟环境中的依赖齐全且不存在冲突。
* 项目代码中需要定制的的文件路径等配置正确。
* 模型参数能正确保存和载入。
* 数据集正确，可通过校验和验证其完整性。

### 第二步

使用pip/conda将虚拟环境的信息保存到requirements.txt或environment.yml文件中，确保虚拟环境可复现。

### 第三步

在README文件中作项目介绍，包括模型介绍、数据集介绍、评测结果、项目代码结构与复现方式、版权声明等。

### 第四步

使用git lfs标记项目中的大文件，其余操作和常规git操作相同。

由于项目中存在数据集、模型参数等大文件，需要使用`git lfs`工具来跟踪大文件。[Git LFS官网](https://git-lfs.com/)上有它安装和使用的详细说明。

安装完git lfs后，我们执行命令`pip install huggingface_hub`安装`huggingface-cli`命令行工具，然后去Hugging Face官网创建一个write token，然后执行`huggingface-cli login`并输入token值，以建立安全的传输通道。我们可以通过`huggingface-cli whoami`和`huggingface-cli env`来查看当前状态。当然，在本地创建SSH密钥对并将公钥上传到官网也可以实现认证。

根据Hugging Face官网上提出的一些issue，执行`git remote set-url origin https://<user_name>:<token>@huggingface.co/<repo_path>`可以避免一些认证失败问题，或者使用SSH协议对应的地址。

如果要创建新的模型项目，先执行`huggingface-cli repo create <model_name>`在官网上创建一个新的远程仓库，然后使用`git clone`克隆到本地，然后把本地的项目文件全部转移到其中。

如果要上传的文件大小大于5GB，需要执行`huggingface-cli lfs-enable-largefiles <./path/to/your/local_repo>`，否则会被服务器拒绝。

使用`git lfs track <file_name>`的方式跟踪项目中的大文件，这与直接修改项目中的.gitattributes文件等价，注意.gitattributes不能被.gitignore包括。如果大文件没有被git lfs跟踪，那么在push时可能会遭到服务器的拒绝。

这里需要注意，项目的.git文件中不能有大文件，也就是说，项目的commit历史中不允许有没被git lfs track的大文件。因为git为了提高性能，每一个项目版本都重新保存了一遍改动文件的副本，如果在某个大文件被git lfs track之前某次commit就包含了它，那么.git中对应那次commit的文件夹中就会保存一份当时commit的大文件副本，这样.git就会变得很大。所以，所有大文件在第一次被纳入某个版本前都应被git lfs track，不然.git中就会留有它的副本，这种情况下的push请求会被Hugging Face拒绝，此时只能调整commit历史或者删除.git重置仓库。

所以对于一个新项目或者有新纳入大文件的项目，在正式执行git指令前，应该执行`huggingface-cli lfs-enable-largefiles <./path/to/your/local_repo>`和`git lfs track <file_name>`保证所有大文件在commit前都处于被git lfs追踪的状态。

使用`git add`，`git commit`，`git push`完成项目上传。

**注意，Hugging Face官网在中国大陆境内访问受限，上述过程中所有与其交互的过程均需使用ProxyChains等工具代理流量。**

#### 使用Hugging Face镜像站

一种解决国内访问Hugging Face受限问题的方式是使用镜像站，例如[HF-Mirror](https://hf-mirror.com/)。具体使用方式可以参见镜像网站上的说明。简单来说，可以通过`export HF_ENDPOINT=<url_of_mirror>`来修改huggingface-cli的数据源，也可以克隆镜像站的仓库避免科学上网。笔者目前只使用过镜像站来克隆仓库或下载文件，没有尝试过上传仓库（即将git remote指向的远程仓库置为镜像站的相应仓库），也许镜像站能在git push后提供中转功能。

#### 问题遗留

笔者在往Hugging Face官网仓库push时遇到了一些问题，暂时没有push成功的过程。下面对笔者的操作流程进行叙述。

首先，笔者下载并安装并初始化了git lfs，然后下载了huggingface-cli并使用创建的write token登录，使用`huggingface-cli whoami`表明处于登录状态，笔者也上传了与本地机器上的密钥对应的公钥，使用`ssh -T git@hf.co`验证SSH认证没有问题。

笔者接着使用`huggingface-cli repo create`命令在官网创建了一个空仓库（只包含.gitattributes文件），然后使用ProxyChains代理git clone命令将仓库成功克隆到了本地，笔者接着将本地的一个项目的除.git外的所有文件转移到克隆下来的文件夹中，然后将这个新的文件夹作为项目的根目录。

笔者接着在项目根目录中执行`huggingface-cli lfs-enable-largefiles .`以表明这个项目中有大文件，然后笔者使用`git lfs track`跟踪了所有大于等于5MB的文件。

笔者配置了项目的本地配置，用户名、邮箱都与Hugging Face上的账号一致，git remote地址设置为`https://<user_name>:<token>@huggingface.co/<repo_path>`。

然后笔者使用git add/commit/push尝试上传项目。在git push时一直停留在Upload large file的进度条的零点，上传速度也显示为0。笔者多次执行git push命令，有时会输出`fatal: unable to access 'https://huggingface.co/<repo_path>/': gnutls_handshake() failed: Error in the pull function.`，有时就是卡在上述进度条起始处长时间没有进展。这里的git push通过ProxyChains代理流量，否则无法基于https协议与Hugging Face通信。

笔者能够确认这不是认证的问题，因为能够进入Upload large file的过程说明了认证成功。笔者将git remote地址中的token改错一位后再次执行git push，报错结果会明确指出认证失败，而不是停留在Upload large file的零点无法动弹。

理论上来说是否使用代理不会产生影响，为了验证这一点，笔者在`ssh -T git@hf.co`输出登录成功的情况下，将git remote远程仓库地址改为使用SSH协议访问的地址，即`git@hf.co:<repo_path>`，然后再执行git push，结果依然停留再Upload large file的进度条零点，无论等待多长时间。这表明问题的产生过程中使用代理服务器不是决定性因素。

问题也许源于笔者上述操作过程中的疏漏，但笔者反复检查和查阅常见教程、讨论与资料后并没有发现有误操作或漏操作，笔者没有详细浏览所有的错误相关讨论，也许问题出在笔者目前未知的位置；问题也许源于git lfs的传输端或Hugging Face官网的接受端，这没有明确的证据表征。

笔者最后尝试将git remote地址指向HF-Mirror的镜像仓库，因为服务器在国内，所以直接执行git push。这次Upload large files进度条正常推进，上传速度为正常的速度。但是在上传到某个特定进度时，上传速度会变为0，进度会卡住不动，等待一段时间后报错`error: failed to push some refs to <remote_repo_url>`。笔者尝试了多次，结果完全相同。

截至目前，笔者没有成功上传包含大文件的项目到Hugging Face的经历，也没有找出造成上述问题的原因。后续读者会继续阅读相关资讯，总结经验并继续做合理的尝试，如有新的进展，读者会在这里更新。